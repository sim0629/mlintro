\documentclass[a4paper,9pt]{article}

\usepackage{kotex}
\usepackage{datetime}
\usepackage{fullpage}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{float}
\usepackage[skip=5pt]{caption}

\graphicspath{ {images/} }

\newdateformat{koreandate}{\THEYEAR년 \twodigit{\THEMONTH}월 \twodigit{\THEDAY}일}

\renewcommand{\abstractname}{초록}
\renewcommand{\figurename}{그림}
\renewcommand{\tablename}{표}
\renewcommand{\contentsname}{목차}
%\renewcommand{\listfigurename}{그림 목차}
%\renewcommand{\listtablename}{표 목차}

\linespread{1.3}
\pagenumbering{arabic}
\setlength\columnsep{20pt}
\setlist[enumerate]{itemsep=0mm}

\begin{document}

\title{선행 연구(Coates et al., 2011)에 기초한 \\
CIFAR-10 이미지 분류기 구현 및 실험}
\author{기계학습개론 기말 프로젝트 보고서 \\
컴퓨터공학부 2009-11744 심규민}
\date{\koreandate\today}

\maketitle

\begin{abstract}
(TODO)
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\pagebreak

\begin{multicols}{2}

\section{서론}

Coates et al.(2011)의 연구에서는 무감독 학습을 통해 얻은 feature로 단일 층(SVM)으로 구성된 이미지 분류기를 만들고, 무감독 학습 알고리즘과 하이퍼 파라미터를 바꿔보며 성능 면에서 비교를 하였다.
본 실험에서는 이 선행 연구에서 구현한 분류기에 기초하여, 하이퍼 파라미터는 선행 연구에서 찾아낸 가장 좋은 성능을 내는 것으로 고정하고, feature extraction에 사용한 무감독 학습 알고리즘(특히, K-means 알고리즘)과 pooling 방식을 다양하게 추가 구현하여 선행 연구와 비교해 보았다.

먼저, 선행 연구에서는 feature 학습에 다른 복잡한 알고리즘들에 비해 상대적으로 간단한 K-means 알고리즘을 사용했을 때 가장 좋은 성능을 냈다고 강조하였다.
그러나 실은 가장 기본적인 K-means(hard) 알고리즘을 사용한 것이 아니라 triangle activation을 더한 K-means(triangle) 알고리즘을 사용하였다.
성능(분류 정확도)에 있어서도 K-means(hard) 알고리즘을 사용했을 때에는 다른 알고리즘들을 사용했을 때 보다 낮은 성능을 보였으며, K-means(triangle) 알고리즘을 사용했을 때 비로소 가장 좋은 성능을 내었다.
이 사실에 주목하여 soft한 특성을 갖도록 다양하게 변형한 K-means 알고리즘들에 대해서도 실험 해보기로 하였다.
또한, 선행 연구에서는 convolutional feature extraction에 사용한 receptive field 크기, stride, feature 개수, whitening 여부 등의 하이퍼 파라미터들은 다양하게 바꿔보며 실험한 데에 반해서, pooling 방식은 sum만을 사용하였다.
이 사실에 의문을 갖고 average pooling, maximum pooling, stochastic pooling(Zeiler et al., 2013), stochastic max-pooling(Huang et al., 2015) 등의 다양한 pooling 방식에 대해서도 실험 해보기로 하였다.
마지막으로, 선행 연구에서는 분류 정확도를에 대한 오차 범위가 드러나 있지 않다.
다양한 soft K-means 알고리즘과 pooling 방식에 대한 비교를 더욱 정밀히 하기 위해, 여러번 실험하여 오차 범위까지 산출하여 분석 해보기로 하였다.

앞으로 본 보고서에서는 구현의 명확성을 위해 선행 연구의 방법을 더 자세히 설명하고, 본 실험을 위해 추가로 구현한 사항을 명시한 뒤, 실험 결과를 분석하였다.

\section{선행 연구}

선행 연구(ibid.)에서 가장 좋은 성능을 낸 이미지 분류기의 구체적인 알고리즘은 다음과 같다.
\begin{enumerate}
\item 랜덤 patch 샘플링
\item K-means를 이용한 feature extractor 생성
\item Convolutional feature 추출 (training)
\item Sum over quadrant pooling (training)
\item SVM 분류기 학습
\item Convolutional feature 추출 (testing)
\item Sum over quadrant pooling (testing)
\item 학습한 SVM으로 분류
\end{enumerate}
전체는 크게 학습 단계(1-5)와 분류 단계(6-8)로 나뉜다.
이 중 convolutional feature 추출과, pooling은 training 데이터와 testing 데이터 모두에게 공통적으로 적용된다.
각 세부 단계의 구체적인 구현은 다음과 같다.

\subsection{랜덤 patch 샘플링}

CIFAR-10의 training 데이터는 50000개의 32x32픽셀 컬러(RGB의 3채널) 이미지와 분류 레이블로 구성되어 있다.
즉,
\begin{align*}
    X_{train} &= \{ \mathbf{x}^{(i)} \}_{i=1}^{50000} ( \mathbf{x}^{(i)} \in [0, 1]^{32 \times 32 \times 3} ) \\
    Y_{train} &= \{ y^{(i)} \}_{i=1}^{50000} ( y^{(i)} \in \{0, 1, ..., 9\} )
\end{align*}
$X_{train}$에서 무작위로 6x6x3 크기의 patch를 400000개 뽑는다.
이 때 공평하게 각각의 $\mathbf{x}^{(i)}$에서 8개씩 뽑는다.
이렇게 하여,
\begin{align*}
    P_{sample} &= \{ \mathbf{p}^{(i)} \}_{i=1}^{400000} ( \mathbf{p}^{(i)} \in [0, 1]^{6 \times 6 \times 3} )
\end{align*}
를 얻는다.

\subsection{Feature extractor 생성}
\label{sec:feature_extractor}

먼저, K-means 알고리즘으로 $P_{sample}$를 $K(=1600)$개의 그룹으로 나누는, 각 그룹의 중심($C$)을 얻는다.
\begin{align*}
    C &= \{ \mathbf{c}^{(i)} \}_{i=1}^{1600} ( \mathbf{c}^{(i)} \in [0, 1]^{6 \times 6 \times 3} )
\end{align*}
$P_{sample}$의 크기가 400000으로 너무 크므로 1000개씩 mini-batch 방식을 사용한다.
Iteration 횟수는 50회로 고정한다.
K-means 알고리즘 자체에 대한 설명은 trivial 하므로 생략한다.

다음으로, $C$를 이용하여 feature extractor $\mathbf{f}$를 만든다.
$f$는 다음 단계인 convolutional feature 추출에서 사용할 함수인데, $\mathbf{x}^{(i)}$에서 잘라낸 6x6x3 크기의 어떤 patch $\mathbf{p}^{*}$를 $\mathbf{c}^{(i)}$들과의 거리(유클리드 거리의 제곱)로 이루어진 $K$차원의 벡터로 변형하는 함수 $\mathbf{f}'$을 변형해서 만든다.
일단 $\mathbf{f}'$은
\begin{align*}
    \mathbf{f}' &= (f_{1}', f_{2}', ..., f_{1600}') \\
    f_{i}'(\mathbf{p}^{*}) &= || \mathbf{p}^{*} - \mathbf{c}^{(i)} ||_2^2
\end{align*}
이며, $\mathbf{f}$는 $\mathbf{f}'$의 결과 벡터에서 각 원소의 평균값을 구하고, 평균 이상인 원소는 0으로 평균 이하인 원소는 평균값에서 자신의 값을 뺀 값으로 설정해준 것이다.
$\mathbf{f}$의 의미를 생각해보면, 중심점 $\mathbf{c}^{(i)}$와 거리가 가까울(작을) 수록 큰 activation을 주기 위해 값에 마이너스를 붙여 뒤집어 주었고, 뒤집은 값에 평균을 더해 평균 거리보다 가까운 중심점에 대한 activation들을 양수로 만들고, 평균 거리보다 먼 중심점에 대해서는 음의 activation을 주는 대신 0을 준 것이다.
즉,
\begin{align*}
    \mathbf{f} &= (f_{1}, f_{2}, ..., f_{1600}) \\
    f_{i}(\mathbf{p}^{*}) &= \text{max} ( 0, \text{avg} (\mathbf{f}'(\mathbf{p}^{*})) - f_{i}'(\mathbf{p}^{*}) )
\end{align*}
와 같다.

\subsection{Convolutional feature 추출}

Translation-invariant한 feature 벡터를 얻기 위해, convolutional feature 추출을 한다.
각각의 입력 이미지 $\mathbf{x}^{(i)}$에 대해, receptive field 크기 $w(=6)$, stride $s(=1)$로 patch를 꺼낸다.
이미지의 크기는 채널을 제외하면 32x32이므로 한 이미지에 대해 27x27개($\because (32-w)/s+1=27$)의 patch가 나온다.
이렇게 꺼낸 각각의 patch를 $\mathbf{f}$에 통과시키면, 한 이미지 당 $K(=1600)$차원의 벡터가 27x27개 생긴다.
종합하면, convolutional feature 추출을 통해 32x32x3 크기였던 입력 이미지는 27x27x1600 크기의 이미지 표현으로 확장된다(그림 \ref{fig:feature_extraction} 왼쪽).

\subsection{Sum over quadrant pooling}

Convolution feature 추출에서 보았듯이 입력 이미지에 비해 이미지 표현의 크기는 훨씬 크다.
이미지 표현에 pooling을 적용함으로써 weight sharing을 하여 차원을 줄인 feature 벡터를 구한다.
$K$를 제외하고 생각했을 때, 27x27 크기의 이미지 표현을 사분면으로 나누고(14x14, 14x13, 13x14, 13x13), 각 사분면에 대해 모든 값을 더한다.
이것을 $K$개의 feature에 대해 각각 적용하면, 최종적으로 $4K(=6400)$차원의 feature 벡터가 얻어진다(그림 \ref{fig:feature_extraction} 오른쪽).

\begin{figure}[H]
\includegraphics[width=\linewidth]{feature_extraction}
\caption{Feature 벡터 추출 과정 (Coates et al., 2011)}
\label{fig:feature_extraction}
\end{figure}

Feature 추출에 관련된 모든 작업을 다음과 같이 하나의 함수 $\Phi$로 표현해볼 수 있다.
\begin{align*}
    \Phi &\colon X \to [0, 1]^{6400} \\
    \Phi(\mathbf{x}) &= (\text{feature vector})
\end{align*}

\subsection{SVM 분류기}

$\Phi(X_{train})$을 입력으로 하고, $Y_{train}$을 출력으로 하여, SVM(L2) 분류기를 학습 시킨다.
이 학습한 분류기를 가지고 $\Phi(X_{test})$를 분류하게 된다.
본 실험에서는 선행 연구에서 구현한 SVM을 그대로 사용하였다.
SVM 자체에 대한 설명은 생략한다.

\section{추가 구현}

본 실험을 위해, 일단 Coates의 웹페이지에서 데모 코드를 얻었다.
MATLAB으로 작성되어 있었으며, 여기에 코드를 추가하여 실험하였다.

\subsection{여러 soft한 K-means 알고리즘}

\ref{sec:feature_extractor}절을 주의 깊게 보면, 선행 연구에서 주목 할만한 점이 있다.
선행 연구 논문에서는 가장 가까운 중심점에 대한 activation만 1로 한 것을 K-means(hard)로, $\mathbf{f}$ 처럼 평균 이하를 버려서 activation을 바꿔준 것을 K-means(triangle)로 표기 하였다.
그리고 여러가지 무감독 학습(Auto-encoder, GMM 등) 중에 하나로 K-means(hard)와 K-means(triangle)을 구별하여 소개하였다.
그러나 이 부분은 misleading을 유발한다.
사실은 두 K-means 알고리즘이 중심점을 구하는 과정까지는 완벽히 동일함을 알 수 있다.
(E-M 알고리즘에서 responsibility를 1-of-N 대신 softmax 등의 확률을 사용하여 iteration을 도는) Soft K-means 알고리즘을 K-means(triangle) 알고리즘과 비교해볼 때 확연히 다르다.
다시 말하면, K-means(triangle)은 soft한 K-means 알고리즘이 아니다.
본 연구에서는 데모 코드를 보고 나서야, 이 부분을 misleading 했다고 알게 되었다.
결국 여러 soft한 K-means 알고리즘을 구현하여 비교하려던 초기 계획은 더이상 유효하지 않게 되었고, 따라서 진행할 수 없었다.

GMM을 봤을 때에도 성능이 좋지 않았다.
클러스터링 알고리즘 보다는 activation을 어떻게 구하는지가 중요
이건 pooling의 일부로도 볼 수 있다
(TODO)

\subsection{여러 pooling 방식}

(TODO)

\subsection{기타 구현}

오차 분석
confusion matrix
imwrite?
(TODO)

\section{실험 결과}

\section{결론}

triangle k-means는 activation에 ReLU를 적용한 것과 사실상 같음

의의
오차 분석
misleading 지적

\section*{참고 문헌}

\begin{itemize}
\item Coates, A., Ng, A. Y., \& Lee, H. (2011). An analysis of single-layer networks in unsupervised feature learning. In \textit{International conference on artificial intelligence and statistics}.
\item Huang, Y., Sun, X., Lu, M., \& Xu, M. (2015). Channel-Max, Channel-Drop and Stochastic Max-Pooling. In \textit{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops}.
\item Zeiler, M. D., \& Fergus, R. (2013). Stochastic pooling for regularization of deep convolutional neural networks. \textit{arXiv preprint arXiv:1301.3557}.
\end{itemize}

\end{multicols}

\end{document}
